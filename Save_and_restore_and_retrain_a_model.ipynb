{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Save and restore a model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/gauravbansal98/Save-and-Restore-a-model-in-tensorflow/blob/master/Save_and_restore_and_retrain_a_model.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "P61dlS1Fv8OE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "f6aca3d7-3e88-44b2-d314-9dd314d43b96"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PInJJ_Yv0Sgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bfeda4f3-5c3e-4098-d9f9-c5b993213a0c"
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\r\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MXiZYsuD0Uje",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hXaWAnEP0pAr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "ee1f7a6d-57ae-413a-a9b6-57f71b0c1742"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"drive/Uploaded on github/mnist dataset using rnn\", one_hot = True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-bd80a8df6832>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting drive/Uploaded on github/mnist dataset using rnn/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting drive/Uploaded on github/mnist dataset using rnn/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting drive/Uploaded on github/mnist dataset using rnn/t10k-images-idx3-ubyte.gz\n",
            "Extracting drive/Uploaded on github/mnist dataset using rnn/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "52zmzjXw5rby",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops import rnn, rnn_cell\n",
        "tf.reset_default_graph()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uQbfNpjt0ucL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rnn_size = 128\n",
        "no_of_nodes_in_output_layer = 10\n",
        "chunk_size = 56\n",
        "no_of_chunk = 14\n",
        "batch_size = 128\n",
        "hm_epochs = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VflAwafR1hAK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(dtype = tf.float32, shape = [None, no_of_chunk, chunk_size], name = 'input_labels')\n",
        "y = tf.placeholder(dtype = tf.float32, shape = [None, None], name = 'output_labels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWn_PCxl1kmt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights = { 'weights' : tf.Variable(tf.random_normal([rnn_size, no_of_nodes_in_output_layer])),\n",
        "           'biases' : tf.Variable(tf.random_normal([1, no_of_nodes_in_output_layer])) }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iKk4uX982WjT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def recurrent_neural_network(x):\n",
        "  with tf.name_scope('Neural_Network'):\n",
        "    x = tf.transpose(x, [1,0,2])\n",
        "    x = tf.reshape(x, [-1, chunk_size])\n",
        "    x = tf.split(x, no_of_chunk, 0)\n",
        "    cell = tf.nn.rnn_cell.BasicLSTMCell(rnn_size, name = 'LSTM_CELL')\n",
        "    outputs, state = tf.nn.static_rnn(cell, x, dtype = tf.float32)\n",
        "\n",
        "    output = tf.add(tf.matmul(outputs[-1], weights['weights']), weights['biases'], name = 'last_layer_output')\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_A8fcP3z3lgk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2c473457-2cf0-452f-cf49-4d9c6d27a888"
      },
      "cell_type": "code",
      "source": [
        "os.chdir('drive/Uploaded on github/Save and Restore a model in tensorflow')\n",
        "\n",
        "prediction = recurrent_neural_network(x)\n",
        "\n",
        "y_pred = tf.nn.softmax(prediction, name = \"y_pred\")\n",
        "\n",
        "saver = tf.train.Saver(tf.trainable_variables())\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y), name = \"cost\")\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for i in range(hm_epochs):\n",
        "    epoch_loss = 0\n",
        "    for j in range(int(mnist.train.num_examples/batch_size)):\n",
        "      epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
        "      epoch_x = epoch_x.reshape((batch_size,no_of_chunk,chunk_size))\n",
        "      o, c = sess.run([optimizer, cost], feed_dict = {x : epoch_x, y : epoch_y})\n",
        "      epoch_loss += c\n",
        "    print('epoch' , i, 'completed out of ', hm_epochs, 'loss ', epoch_loss)\n",
        "\n",
        "  saver.save(sess, './saved_model')\n",
        "  \n",
        "  correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
        "\n",
        "  \n",
        "  accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
        "\n",
        "  print('Accuracy:',accuracy.eval({x:mnist.test.images.reshape(-1,no_of_chunk,chunk_size), y:mnist.test.labels})) "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 completed out of  1 loss  245.44157840311527\n",
            "Accuracy: 0.9453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eNvgPcNktlOJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "432fa033-21e6-48a8-8a75-29b25510e418"
      },
      "cell_type": "code",
      "source": [
        "hm_epochs = 2\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "saver = tf.train.import_meta_graph('saved_model.meta')\n",
        "\n",
        "print(\"meta graph loaded\")\n",
        "\n",
        "saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
        "\n",
        "graph = tf.get_default_graph()\n",
        "\n",
        "x = graph.get_tensor_by_name(\"input_labels:0\")\n",
        "\n",
        "y = graph.get_tensor_by_name(\"output_labels:0\")\n",
        "\n",
        "last_layer_output = graph.get_tensor_by_name(\"Neural_Network/last_layer_output:0\")\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = last_layer_output, labels = y), name = \"cost\")\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(name = \"sss\")\n",
        "\n",
        "minimize = optimizer.minimize(cost) \n",
        "\n",
        "sess.run(tf.variables_initializer(optimizer.variables()))\n",
        "\n",
        "var = tf.trainable_variables()\n",
        "\n",
        "var_before = sess.run(var)\n",
        "\n",
        "for i in range(2):\n",
        "  epoch_loss = 0\n",
        "  for j in range(int(mnist.train.num_examples/batch_size)):\n",
        "    epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
        "    epoch_x = epoch_x.reshape((batch_size,no_of_chunk,chunk_size))\n",
        "    o, c = sess.run([minimize, cost], feed_dict = {x : epoch_x, y : epoch_y})\n",
        "    epoch_loss += c\n",
        "  print('epoch' , i, 'completed out of ', hm_epochs, 'loss ', epoch_loss)\n",
        "\n",
        "new_saver = tf.train.Saver(tf.trainable_variables())\n",
        "new_saver.save(sess, './saved_model')\n",
        "\n",
        "var = tf.trainable_variables()\n",
        "\n",
        "var_after = sess.run(var)\n",
        "\n",
        "correct = tf.equal(tf.argmax(last_layer_output, 1), tf.argmax(y, 1))\n",
        "  \n",
        "accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
        "\n",
        "print('Accuracy:',sess.run(accuracy, feed_dict = {x:mnist.test.images.reshape(-1,no_of_chunk,chunk_size), y:mnist.test.labels})) \n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "meta graph loaded\n",
            "INFO:tensorflow:Restoring parameters from ./saved_model\n",
            "epoch 0 completed out of  2 loss  26.562956606037915\n",
            "epoch 1 completed out of  2 loss  19.843446370447055\n",
            "Accuracy: 0.9823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uOCLgZ69xH6y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}